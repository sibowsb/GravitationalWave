{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import h5py\n",
    "import copy\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "f=h5py.File('dataset.h5','r')\n",
    "testsig=list(f['test'])\n",
    "trainsig=list(f['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(space):\n",
    "    def generator_f(data,size,snr,X,Y_):\n",
    "        signal=np.zeros([size,8192])\n",
    "        label=np.zeros([size,2])\n",
    "        data=random.sample(data,size/2)\n",
    "        data=np.array(data)\n",
    "        for i in range(size):\n",
    "            if i%2==0:\n",
    "                r=random.randint(0,1638)\n",
    "                label[i]=[0,1]\n",
    "                signal[i,0:8191-r:1]=data[i/2,r:8191:1]*snr\n",
    "                signal[i]+=np.random.normal(0,1,8192)\n",
    "                signal[i]=signal[i]/np.std(signal[i])\n",
    "            else:\n",
    "                label[i]=[1,0]\n",
    "                signal[i]=np.random.normal(0,1,8192)\n",
    "        feed_dict={\n",
    "            X:signal,\n",
    "            Y_:label,\n",
    "        }\n",
    "        return feed_dict    \n",
    "\n",
    "    def generator_r(data,size,snr,X,Y_):\n",
    "        signal=np.zeros([size,8192])\n",
    "        label=np.zeros([size,2])\n",
    "        data=random.sample(data,size/2)\n",
    "        data=np.array(data)\n",
    "        for i in range(size):\n",
    "            if i%2==0:\n",
    "                r=random.randint(0,1638)\n",
    "                label[i]=[0,1]\n",
    "                signal[i,0:8191-r:1]=data[i/2,r:8191:1]*random.uniform(snr,2)\n",
    "                signal[i]+=np.random.normal(0,1,8192)\n",
    "                signal[i]=signal[i]/np.std(signal[i])\n",
    "            else:\n",
    "                label[i]=[1,0]\n",
    "                signal[i]=np.random.normal(0,1,8192)\n",
    "        feed_dict={\n",
    "            X:signal,\n",
    "            Y_:label,\n",
    "        }\n",
    "        return feed_dict    \n",
    "    \n",
    "    sess=tf.Session()\n",
    "    k1=space['k1']\n",
    "    k2=space['k2']\n",
    "    k3=space['k3']\n",
    "    c1=space['c1']\n",
    "    c2=space['c2']\n",
    "    c3=space['c3']\n",
    "    c4=space['c4']\n",
    "    print(' k1: '+str(k1)+' k2: '+str(k2)+' k3: '+str(k3)+' c1: '+str(c1)+' c2: '+str(c2)+' c3: '+str(c3)+' c4: '+str(c4))\n",
    "#initial weight\n",
    "    def weight_variable(name,shape):\n",
    "        return tf.get_variable(name,shape=shape,initializer=tf.contrib.layers.xavier_initializer())\n",
    "#intial bias\n",
    "    def bias_variable(name,shape):\n",
    "        return tf.get_variable(name,shape=shape,initializer=tf.constant_initializer(0.1))\n",
    "#placeholder\n",
    "    with tf.name_scope('Input'):\n",
    "        X=tf.placeholder(tf.float32,[None,8192])\n",
    "    with tf.name_scope('Label'):\n",
    "        Y_=tf.placeholder(tf.float32,[None,2])\n",
    "\n",
    "#reshape layer\n",
    "    with tf.name_scope('Reshape_layer'):\n",
    "        XX=tf.reshape(X,[-1,8192,1,1])\n",
    "#convolution layer 1\n",
    "    w_conv1=weight_variable('w_conv1',[k1,1,1,c1])\n",
    "    b_conv1=bias_variable('b_conv1',[c1])\n",
    "    with tf.name_scope('Convolution_layer1'):\n",
    "        conv1=tf.nn.conv2d(XX,w_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "    print(conv1.shape)\n",
    "\n",
    "#activation layer 1\n",
    "    with tf.name_scope('Relu_layer1'):\n",
    "        h_conv1=tf.nn.relu(conv1+b_conv1)\n",
    "\n",
    "#pooling layer 1\n",
    "    with tf.name_scope('Pooling_layer1'):\n",
    "        h_pool1=tf.nn.max_pool(h_conv1,[1,4,1,1],strides=[1,4,1,1],padding='SAME')\n",
    "    print(h_pool1.shape)\n",
    "\n",
    "#convolution layer 2\n",
    "    w_conv2=weight_variable('w_conv2',[k2,1,c1,c2])\n",
    "    b_conv2=bias_variable('b_conv2',[c2])\n",
    "    with tf.name_scope('Convolution_layer2'):\n",
    "        conv2=tf.nn.atrous_conv2d(h_pool1,w_conv2,rate=4,padding='SAME')\n",
    "    print(conv2.shape)\n",
    "\n",
    "#activation layer 2\n",
    "    with tf.name_scope('Relu_layer2'):\n",
    "        h_conv2=tf.nn.relu(conv2+b_conv2)\n",
    "\n",
    "#pooling layer 2\n",
    "    with tf.name_scope('Pooling_layer2'):\n",
    "        h_pool2=tf.nn.max_pool(h_conv2,ksize=[1,4,1,1],strides=[1,4,1,1],padding='SAME')\n",
    "    print(h_pool2)\n",
    "\n",
    "#convolution layer 3\n",
    "    w_conv3=weight_variable('w_conv3',[k3,1,c2,c3])\n",
    "    b_conv3=bias_variable('b_conv3',[c3])\n",
    "    with tf.name_scope('Convolution_layer3'):\n",
    "        conv3=tf.nn.atrous_conv2d(h_pool2,w_conv3,rate=4,padding='SAME')\n",
    "    print(conv3)\n",
    "\n",
    "#activation layer 3\n",
    "    with tf.name_scope('Relu_layer3'):\n",
    "        h_conv3=tf.nn.relu(conv3+b_conv3)\n",
    "\n",
    "#pooling layer 3\n",
    "    with tf.name_scope('Pooling_layer3'):\n",
    "        h_pool3=tf.nn.max_pool(h_conv3,ksize=[1,4,1,1],strides=[1,4,1,1],padding='SAME')\n",
    "    print(h_pool3.shape)\n",
    "\n",
    "#flatten layer\n",
    "    with tf.name_scope('Flatten_layer'):\n",
    "        h_flatten=tf.reshape(h_pool3,[-1,128*c3])\n",
    "    print(h_flatten.shape)\n",
    "\n",
    "#linear layer 1\n",
    "    w_linear1=weight_variable('w_linear1',[128*c3,c4])\n",
    "    b_linear1=bias_variable('b_linear1',[c4])\n",
    "\n",
    "#activation layer 4\n",
    "    with tf.name_scope('Relu_layer4'):\n",
    "        h_linear1=tf.nn.relu(tf.matmul(h_flatten,w_linear1)+b_linear1)\n",
    "    \n",
    "#linear layer 2\n",
    "    w_linear2=weight_variable('w_linear2',[c4,2])\n",
    "    b_linear2=bias_variable('b_linear2',[2])\n",
    "\n",
    "#activation layer 5\n",
    "    Ylogits=tf.matmul(h_linear1,w_linear2)+b_linear2\n",
    "    with tf.name_scope('Output'):\n",
    "        Y=tf.nn.softmax(Ylogits)\n",
    "\n",
    "#loss function\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits,labels=Y_)\n",
    "    cross_entropy=tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#accuracy\n",
    "    is_correct=tf.equal(tf.argmax(Y,1),tf.argmax(Y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(is_correct,tf.float32))*100\n",
    "\n",
    "#optimization\n",
    "    optimizer=tf.train.AdamOptimizer(0.001)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_step=optimizer.minimize(cross_entropy,global_step=global_step)\n",
    "#run\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    try:\n",
    "        for i in range(30000):\n",
    "            snr=0.3\n",
    "            feed_dict=generator_r(trainsig,50,snr,X,Y_)\n",
    "            sess.run(train_step,feed_dict=feed_dict)\n",
    "        test=generator_f(testsig,1480,snr,X,Y_)\n",
    "        a=sess.run(accuracy,feed_dict=test)\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        print('accuracy: '+str(a))\n",
    "        return -a\n",
    "    except Exception,e:\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        print e\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space={\n",
    "    'k1':hp.choice('k1',[4,8,16,32]),\n",
    "    'k2':hp.choice('k2',[4,8,16,32]),\n",
    "    'k3':hp.choice('k3',[4,8,16,32]),\n",
    "    'c1':hp.choice('c1',[8,16,32,64,128]),\n",
    "    'c2':hp.choice('c2',[16,32,64,128,256]),\n",
    "    'c3':hp.choice('c3',[16,32,64,128,256]),\n",
    "    'c4':hp.choice('c4',[16,32,64,128,256])\n",
    "    \n",
    "}\n",
    "best=fmin(fn=f,space=space,algo=tpe.suggest,max_evals=50000)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
